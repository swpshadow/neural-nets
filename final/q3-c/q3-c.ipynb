{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceramic-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "healthy-client",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-e02ed463d761>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"year\"][i] = int(df[\"Date\"][i][0:4])\n",
      "<ipython-input-2-e02ed463d761>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"month\"][i] = int(df[\"Date\"][i][5:7])\n",
      "<ipython-input-2-e02ed463d761>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"day\"][i] = int(df[\"Date\"][i][8:])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./daily-min-temperatures.csv\")\n",
    "df[\"year\"] = [0]*len(df[\"Date\"])\n",
    "df[\"month\"] = [0]*len(df[\"Date\"])\n",
    "df[\"day\"] = [0]*len(df[\"Date\"])\n",
    "for i in range(len(df[\"year\"])):\n",
    "    df[\"year\"][i] = int(df[\"Date\"][i][0:4])\n",
    "    df[\"month\"][i] = int(df[\"Date\"][i][5:7])\n",
    "    df[\"day\"][i] = int(df[\"Date\"][i][8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "synthetic-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size= 0.2, shuffle=False)\n",
    "train = train[[\"year\", 'month', \"day\", \"Temp\"]].reset_index(drop=True)\n",
    "test = test[[\"year\", 'month', \"day\", \"Temp\"]].reset_index(drop=True)\n",
    "\n",
    "x_train = train[[\"year\", 'month', \"day\"]].values.reshape((train[[\"year\", 'month', \"day\"]].values.shape[0], 1, train[[\"year\", 'month', \"day\"]].values.shape[1]))\n",
    "y_train = train[\"Temp\"].values\n",
    "\n",
    "x_test = test[[\"year\", 'month', \"day\"]].values.reshape((test[[\"year\", 'month', \"day\"]].values.shape[0], 1, test[[\"year\", 'month', \"day\"]].values.shape[1]))\n",
    "y_test = test[\"Temp\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collaborative-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow tutorial\n",
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "               train_df=train[[\"month\", \"day\", \"Temp\"]], val_df=test[[\"month\", \"day\", \"Temp\"]], test_df=test[[\"month\", \"day\",\"Temp\"]],\n",
    "               label_columns=None):\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                               enumerate(train_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "\n",
    "    @property\n",
    "    def example(self):\n",
    "        \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "        result = getattr(self, '_example', None)\n",
    "        if result is None:\n",
    "        # No example batch was found, so get one from the `.train` dataset\n",
    "            result = next(iter(self.train))\n",
    "        # And cache it for next time\n",
    "            self._example = result\n",
    "        return result\n",
    "\n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "          data=data,\n",
    "          targets=None,\n",
    "          sequence_length=self.total_window_size,\n",
    "          sequence_stride=1,\n",
    "          shuffle=True,\n",
    "          batch_size=32,)\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "#     WindowGenerator.split_window = split_window\n",
    "#     WindowGenerator.make_dataset = make_dataset\n",
    "#     WindowGenerator.train = train\n",
    "#     WindowGenerator.val = val\n",
    "#     WindowGenerator.test = test\n",
    "#     WindowGenerator.example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proved-anderson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 15\n",
       "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
       "Label indices: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
       "Label column name(s): ['Temp']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 14\n",
    "wide_window = WindowGenerator(\n",
    "    input_width=k, label_width=k, shift=1,\n",
    "    label_columns=['Temp'])\n",
    "wide_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "overall-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    layers.GRU(64, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "gru_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[\"mse\", tf.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acknowledged-frank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "91/91 [==============================] - 3s 11ms/step - loss: 56.1484 - mse: 56.1484 - mean_absolute_error: 6.1134 - val_loss: 20.7196 - val_mse: 20.7196 - val_mean_absolute_error: 3.6611\n",
      "Epoch 2/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 14.4861 - mse: 14.4861 - mean_absolute_error: 2.9538 - val_loss: 10.4939 - val_mse: 10.4939 - val_mean_absolute_error: 2.5153\n",
      "Epoch 3/40\n",
      "91/91 [==============================] - 1s 8ms/step - loss: 9.1519 - mse: 9.1519 - mean_absolute_error: 2.3163 - val_loss: 7.5316 - val_mse: 7.5316 - val_mean_absolute_error: 2.1307\n",
      "Epoch 4/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 7.6352 - mse: 7.6352 - mean_absolute_error: 2.1277 - val_loss: 6.4110 - val_mse: 6.4110 - val_mean_absolute_error: 1.9739\n",
      "Epoch 5/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 7.0062 - mse: 7.0062 - mean_absolute_error: 2.0445 - val_loss: 5.8875 - val_mse: 5.8875 - val_mean_absolute_error: 1.8970\n",
      "Epoch 6/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 6.6812 - mse: 6.6812 - mean_absolute_error: 2.0021 - val_loss: 5.6134 - val_mse: 5.6134 - val_mean_absolute_error: 1.8663\n",
      "Epoch 7/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 6.4608 - mse: 6.4608 - mean_absolute_error: 1.9736 - val_loss: 5.5534 - val_mse: 5.5534 - val_mean_absolute_error: 1.8650\n",
      "Epoch 8/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 6.2858 - mse: 6.2858 - mean_absolute_error: 1.9473 - val_loss: 5.2327 - val_mse: 5.2327 - val_mean_absolute_error: 1.8038\n",
      "Epoch 9/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 6.1664 - mse: 6.1664 - mean_absolute_error: 1.9313 - val_loss: 5.1615 - val_mse: 5.1615 - val_mean_absolute_error: 1.7982\n",
      "Epoch 10/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 6.0496 - mse: 6.0496 - mean_absolute_error: 1.9155 - val_loss: 5.1303 - val_mse: 5.1303 - val_mean_absolute_error: 1.7949\n",
      "Epoch 11/40\n",
      "91/91 [==============================] - 1s 8ms/step - loss: 5.9719 - mse: 5.9719 - mean_absolute_error: 1.9041 - val_loss: 5.0135 - val_mse: 5.0135 - val_mean_absolute_error: 1.7718\n",
      "Epoch 12/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.9191 - mse: 5.9191 - mean_absolute_error: 1.8968 - val_loss: 4.9816 - val_mse: 4.9816 - val_mean_absolute_error: 1.7722\n",
      "Epoch 13/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.8662 - mse: 5.8662 - mean_absolute_error: 1.8892 - val_loss: 4.9119 - val_mse: 4.9119 - val_mean_absolute_error: 1.7596\n",
      "Epoch 14/40\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 5.8101 - mse: 5.8101 - mean_absolute_error: 1.8806 - val_loss: 4.8992 - val_mse: 4.8992 - val_mean_absolute_error: 1.7513\n",
      "Epoch 15/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.7938 - mse: 5.7938 - mean_absolute_error: 1.8791 - val_loss: 4.9723 - val_mse: 4.9723 - val_mean_absolute_error: 1.7727\n",
      "Epoch 16/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.7518 - mse: 5.7518 - mean_absolute_error: 1.8738 - val_loss: 4.8623 - val_mse: 4.8623 - val_mean_absolute_error: 1.7465\n",
      "Epoch 17/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.7258 - mse: 5.7258 - mean_absolute_error: 1.8702 - val_loss: 4.8924 - val_mse: 4.8924 - val_mean_absolute_error: 1.7605\n",
      "Epoch 18/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.6790 - mse: 5.6790 - mean_absolute_error: 1.8638 - val_loss: 4.8461 - val_mse: 4.8461 - val_mean_absolute_error: 1.7456\n",
      "Epoch 19/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.6681 - mse: 5.6681 - mean_absolute_error: 1.8636 - val_loss: 4.9663 - val_mse: 4.9663 - val_mean_absolute_error: 1.7704\n",
      "Epoch 20/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.6333 - mse: 5.6333 - mean_absolute_error: 1.8569 - val_loss: 4.8025 - val_mse: 4.8025 - val_mean_absolute_error: 1.7347\n",
      "Epoch 21/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.6019 - mse: 5.6019 - mean_absolute_error: 1.8547 - val_loss: 4.9036 - val_mse: 4.9036 - val_mean_absolute_error: 1.7577\n",
      "Epoch 22/40\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 5.5776 - mse: 5.5776 - mean_absolute_error: 1.8498 - val_loss: 4.8785 - val_mse: 4.8785 - val_mean_absolute_error: 1.7531\n",
      "Epoch 23/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.5505 - mse: 5.5505 - mean_absolute_error: 1.8468 - val_loss: 5.0061 - val_mse: 5.0061 - val_mean_absolute_error: 1.7780\n",
      "Epoch 24/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.5231 - mse: 5.5231 - mean_absolute_error: 1.8398 - val_loss: 4.8169 - val_mse: 4.8169 - val_mean_absolute_error: 1.7417\n",
      "Epoch 25/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.5079 - mse: 5.5079 - mean_absolute_error: 1.8381 - val_loss: 4.8538 - val_mse: 4.8538 - val_mean_absolute_error: 1.7508\n",
      "Epoch 26/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.4751 - mse: 5.4751 - mean_absolute_error: 1.8317 - val_loss: 4.8022 - val_mse: 4.8022 - val_mean_absolute_error: 1.7399\n",
      "Epoch 27/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.4594 - mse: 5.4594 - mean_absolute_error: 1.8295 - val_loss: 4.8572 - val_mse: 4.8572 - val_mean_absolute_error: 1.7486\n",
      "Epoch 28/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.4198 - mse: 5.4198 - mean_absolute_error: 1.8224 - val_loss: 4.7671 - val_mse: 4.7671 - val_mean_absolute_error: 1.7279\n",
      "Epoch 29/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.3837 - mse: 5.3837 - mean_absolute_error: 1.8172 - val_loss: 4.7821 - val_mse: 4.7821 - val_mean_absolute_error: 1.7347\n",
      "Epoch 30/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.3730 - mse: 5.3730 - mean_absolute_error: 1.8168 - val_loss: 4.8587 - val_mse: 4.8587 - val_mean_absolute_error: 1.7500\n",
      "Epoch 31/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.3419 - mse: 5.3419 - mean_absolute_error: 1.8109 - val_loss: 4.8763 - val_mse: 4.8763 - val_mean_absolute_error: 1.7511\n",
      "Epoch 32/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.3319 - mse: 5.3319 - mean_absolute_error: 1.8087 - val_loss: 4.8112 - val_mse: 4.8112 - val_mean_absolute_error: 1.7363\n",
      "Epoch 33/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.2886 - mse: 5.2886 - mean_absolute_error: 1.8015 - val_loss: 4.8185 - val_mse: 4.8185 - val_mean_absolute_error: 1.7351\n",
      "Epoch 34/40\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 5.2676 - mse: 5.2676 - mean_absolute_error: 1.7976 - val_loss: 4.8330 - val_mse: 4.8330 - val_mean_absolute_error: 1.7419\n",
      "Epoch 35/40\n",
      "91/91 [==============================] - 1s 8ms/step - loss: 5.2317 - mse: 5.2317 - mean_absolute_error: 1.7909 - val_loss: 4.7949 - val_mse: 4.7949 - val_mean_absolute_error: 1.7384\n",
      "Epoch 36/40\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 5.2253 - mse: 5.2253 - mean_absolute_error: 1.7895 - val_loss: 4.8937 - val_mse: 4.8937 - val_mean_absolute_error: 1.7583\n",
      "Epoch 37/40\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 5.1997 - mse: 5.1997 - mean_absolute_error: 1.7846 - val_loss: 4.8103 - val_mse: 4.8103 - val_mean_absolute_error: 1.7402\n",
      "Epoch 38/40\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 5.1582 - mse: 5.1582 - mean_absolute_error: 1.7778 - val_loss: 4.8893 - val_mse: 4.8893 - val_mean_absolute_error: 1.7545\n",
      "Epoch 39/40\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 5.1618 - mse: 5.1618 - mean_absolute_error: 1.7793 - val_loss: 4.8552 - val_mse: 4.8552 - val_mean_absolute_error: 1.7412\n",
      "Epoch 40/40\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 5.1151 - mse: 5.1151 - mean_absolute_error: 1.7711 - val_loss: 4.8645 - val_mse: 4.8645 - val_mean_absolute_error: 1.7464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16952e910>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model.fit(wide_window.train, epochs=40, validation_data=wide_window.val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "broad-combining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.864458084106445, 4.8644585609436035, 1.7464131116867065]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model.evaluate(wide_window.test, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
